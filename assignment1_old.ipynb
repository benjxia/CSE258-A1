{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258: Assignment 1\n",
    "### Benjamin Xia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:19.717930300Z",
     "start_time": "2023-10-26T01:59:57.594733500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23fc4c26250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user/item ID's, compensation, early_access, and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:53.408937700Z",
     "start_time": "2023-10-26T02:00:34.962524200Z"
    }
   },
   "outputs": [],
   "source": [
    "user_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5)\n",
    "item_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5)\n",
    "\n",
    "itemset = set() # Set of all unique users\n",
    "userset = set() # Set of all unique items\n",
    "U = defaultdict(set)\n",
    "I = defaultdict(set)\n",
    "\n",
    "ft = ['early_access', 'hours_transformed', 'found_funny', 'compensation'] # features unavailable/cannot be approximated in inference\n",
    "def read_json(path):\n",
    "    f: gzip.GzipFile = gzip.open(path)\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = eval(line)\n",
    "        yield entry\n",
    "\n",
    "# Encode userID and itemID as integers\n",
    "def process_data():\n",
    "    global itemset, userset, U, I\n",
    "    data = []\n",
    "    for entry in read_json('train.json.gz'):\n",
    "        data.append(entry)\n",
    "\n",
    "    df: pd.DataFrame = pd.DataFrame(data)\n",
    "    del data\n",
    "    itemset = set(df['gameID'].unique())\n",
    "    userset = set(df['userID'].unique())\n",
    "\n",
    "    U = dict(df.groupby('gameID')['userID'].unique())\n",
    "    I = dict(df.groupby('userID')['gameID'].unique())\n",
    "    U = { g : set(U[g]) for g in U }\n",
    "    I = { u : set(I[u]) for u in I }\n",
    "\n",
    "    df['userIDX'] = user_oe.fit_transform(df[['userID']])\n",
    "    df['itemIDX'] = item_oe.fit_transform(df[['gameID']])\n",
    "    df.rename({'gameID' : 'itemID'}, axis=1, inplace=True)\n",
    "\n",
    "    # Get features for time\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].map(lambda x : x.month)\n",
    "    df['year'] = df['date'].map(lambda x : x.year)\n",
    "    df['day_of_month'] = df['date'].map(lambda x : x.day)\n",
    "    df['day_of_wk'] = df['date'].map(lambda x : x.dayofweek)\n",
    "    df['day_of_yr'] = df['date'].map(lambda x : x.dayofyear)\n",
    "    df['wk_of_yr'] = df['date'].map(lambda x : x.weekofyear)\n",
    "    mme = preprocessing.MinMaxScaler() # Normalize time to range [0, 1]\n",
    "    df[['month', 'year', 'day_of_month', 'day_of_wk', 'day_of_yr', 'wk_of_yr']] = mme.fit_transform(df[['month', 'year', 'day_of_month', 'day_of_wk', 'day_of_yr', 'wk_of_yr']])\n",
    "    df.drop(labels=['hours', 'user_id', 'date'], axis=1, inplace=True)\n",
    "\n",
    "    # Use Fourier features to help with representating cyclic nature of time\n",
    "    for time_unit in [ 'month', 'day_of_month', 'day_of_wk', 'day_of_yr', 'wk_of_yr']:\n",
    "        df[time_unit + '_cos'] = df[time_unit].map(lambda x: np.cos(x * 2 * np.pi))\n",
    "        df[time_unit + '_sin'] = df[time_unit].map(lambda x: np.sin(x * 2 * np.pi))\n",
    "\n",
    "\n",
    "    # Get features that won't be available\n",
    "    df.fillna(value=0, axis=1, inplace=True)\n",
    "    df['compensation'] = df['compensation'].map(lambda x : x if x == 0 else 1)\n",
    "    df[['early_access', 'compensation']] = df[['early_access', 'compensation']].astype(np.int32)\n",
    "\n",
    "    time_label = df['hours_transformed']\n",
    "\n",
    "    return df, time_label\n",
    "\n",
    "# df, time_label = process_data()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for entry in read_json('train.json.gz'):\n",
    "    data.append(entry)\n",
    "\n",
    "df: pd.DataFrame = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>early_access</th>\n",
       "      <th>hours</th>\n",
       "      <th>hours_transformed</th>\n",
       "      <th>found_funny</th>\n",
       "      <th>text</th>\n",
       "      <th>gameID</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>compensation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u70666506</td>\n",
       "      <td>False</td>\n",
       "      <td>63.5</td>\n",
       "      <td>6.011227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If you want to sit in queue for 10-20min and h...</td>\n",
       "      <td>g49368897</td>\n",
       "      <td>76561198030408772</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u18612571</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.263034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I was really not a fan of the gameplay. Games ...</td>\n",
       "      <td>g73495588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u34283088</td>\n",
       "      <td>False</td>\n",
       "      <td>11.9</td>\n",
       "      <td>3.689299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vaas Montenegro is the reason why you should g...</td>\n",
       "      <td>g68047320</td>\n",
       "      <td>76561198057482188</td>\n",
       "      <td>2014-03-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u16220374</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.263034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/10 Wonderful game, simple controls and platf...</td>\n",
       "      <td>g51234623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u01499286</td>\n",
       "      <td>False</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.432959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never knew a guns had THAT many parts!</td>\n",
       "      <td>g25723374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  early_access  hours  hours_transformed  found_funny  \\\n",
       "0  u70666506         False   63.5           6.011227          1.0   \n",
       "1  u18612571         False    0.2           0.263034          NaN   \n",
       "2  u34283088         False   11.9           3.689299          NaN   \n",
       "3  u16220374         False    1.4           1.263034          NaN   \n",
       "4  u01499286         False    1.7           1.432959          NaN   \n",
       "\n",
       "                                                text     gameID  \\\n",
       "0  If you want to sit in queue for 10-20min and h...  g49368897   \n",
       "1  I was really not a fan of the gameplay. Games ...  g73495588   \n",
       "2  Vaas Montenegro is the reason why you should g...  g68047320   \n",
       "3  8/10 Wonderful game, simple controls and platf...  g51234623   \n",
       "4             Never knew a guns had THAT many parts!  g25723374   \n",
       "\n",
       "             user_id        date compensation  \n",
       "0  76561198030408772  2017-05-20          NaN  \n",
       "1                NaN  2017-01-27          NaN  \n",
       "2  76561198057482188  2014-03-06          NaN  \n",
       "3                NaN  2015-06-13          NaN  \n",
       "4                NaN  2015-01-17          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user text and convert to descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# NOTE: Using pretrained sentiment similarity transformer\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_text_embedding():\n",
    "    if not os.path.isfile('./text_embed.npy'): # Generate new descriptors for each review using pretrained transformer\n",
    "        tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        transformer = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2').to(device)\n",
    "        text_embed = np.zeros((len(df), 384))\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, len(df), 1)):\n",
    "                encoded_input = tokenizer(df.iloc[i:i+1]['text'].tolist(),\n",
    "                                        padding=True,\n",
    "                                        truncation=True,\n",
    "                                        return_tensors='pt').to(device)\n",
    "                model_output = transformer(**encoded_input)\n",
    "                embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "                embeddings: torch.Tensor = nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "                text_embed[i:i+1] = embeddings.cpu().numpy()\n",
    "        np.save('text_embed.npy', text_embed)\n",
    "    else: # Text descriptors already computed\n",
    "        text_embed = np.load('./text_embed.npy')\n",
    "\n",
    "    return text_embed\n",
    "\n",
    "text_embed = get_text_embedding()\n",
    "\n",
    "text_cols = ['te_' + str(i) for i in range(text_embed.shape[1])]\n",
    "\n",
    "df.drop('text', axis=1, inplace=True)\n",
    "\n",
    "# Add text descriptor features to dataframe\n",
    "# df = df.join(pd.DataFrame(text_embed, columns=text_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean = df.groupby('userIDX')[ft].mean()\n",
    "item_mean = df.groupby('itemIDX')[ft].mean()\n",
    "df.drop(labels=ft, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_played_train = df.iloc[:150000]\n",
    "df_played_valid = df.iloc[150000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns) + len(user_mean.columns) + len(item_mean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Played dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4.7400e+03,  1.2090e+03,  3.6364e-01,  8.7500e-01,  6.3333e-01,\n",
       "          8.3333e-01,  3.8082e-01,  3.6538e-01, -6.5486e-01,  7.5575e-01,\n",
       "         -6.6913e-01, -7.4314e-01,  5.0000e-01, -8.6603e-01, -7.3249e-01,\n",
       "          6.8077e-01, -6.6312e-01,  7.4851e-01,  2.1429e-01,  4.9497e+00,\n",
       "          3.2643e+01,  0.0000e+00,  5.7895e-01,  3.4550e+00,  1.2456e+00,\n",
       "          2.9240e-02]),\n",
       " tensor([ 1.9290e+03,  1.2090e+03,  3.6364e-01,  8.7500e-01,  6.3333e-01,\n",
       "          8.3333e-01,  3.8082e-01,  3.6538e-01, -6.5486e-01,  7.5575e-01,\n",
       "         -6.6913e-01, -7.4314e-01,  5.0000e-01, -8.6603e-01, -7.3249e-01,\n",
       "          6.8077e-01, -6.6312e-01,  7.4851e-01,  2.1429e-01,  4.9497e+00,\n",
       "          3.2643e+01,  0.0000e+00,  0.0000e+00,  3.7566e+00,  1.6667e-01,\n",
       "          0.0000e+00]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PlayedDataset(Dataset):\n",
    "    def __init__(self, df) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        userID = row['userID']\n",
    "        itemID = row['itemID']\n",
    "        userIDX = row['userIDX']\n",
    "        itemIDX = row['itemIDX']\n",
    "        negaID = random.choice(tuple(itemset.difference(I[userID]))) # Negative item ID\n",
    "        negaIDX = item_oe.transform([[negaID]])[0][0]\n",
    "\n",
    "        # Build positive pair\n",
    "        pos = np.concatenate((row[2:].to_numpy().astype(np.float32),\n",
    "                              user_mean.iloc[userIDX].to_numpy().astype(np.float32),\n",
    "                              item_mean.iloc[itemIDX].to_numpy().astype(np.float32)))\n",
    "        negrow = row.copy()\n",
    "        negrow['userIDX'] = negaIDX\n",
    "        neg = np.concatenate((negrow[2:].to_numpy().astype(np.float32),\n",
    "                              user_mean.iloc[userIDX].to_numpy().astype(np.float32),\n",
    "                              item_mean.iloc[negaIDX].to_numpy().astype(np.float32)))\n",
    "        return torch.from_numpy(pos).to(dtype=torch.float32), torch.from_numpy(neg).to(dtype=torch.float32)\n",
    "\n",
    "played_ds = PlayedDataset(df_played_train)\n",
    "played_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizationMachine(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of a Factorization machine, can be changed to a vanilla\n",
    "    latent factor model by setting n_feature to 0\n",
    "    \"\"\"\n",
    "    def __init__(self, n_user, n_item, n_feature, latent_dim) -> None:\n",
    "        \"\"\"\n",
    "        n_user: Number of unique users\n",
    "        n_item: Number of unique items\n",
    "        n_feature: Number of extra features to use\n",
    "        latent_dim: Dimension of latent representations of users/items/features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.n_feature = n_feature\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.user_latent = nn.Embedding(n_user, latent_dim)\n",
    "        self.item_latent = nn.Embedding(n_item, latent_dim)\n",
    "        self.feat_latent = nn.Embedding(n_feature, latent_dim)\n",
    "        self.user_weight = nn.Embedding(n_user, 1)\n",
    "        self.item_weight = nn.Embedding(n_item, 1)\n",
    "        # \"alpha\" or \"w_0\" term will be absorbed into feat_weight linear's bias\n",
    "        self.feat_weight = nn.Linear(n_feature, 1)\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input shape: batch_size x (user idx, item idx, features) - 2 dimensional\n",
    "        Returns: n x 1 tensor of predictions\n",
    "        \"\"\"\n",
    "        # Case of testing with a single user, item pairing\n",
    "        if len(x.size()) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        # f(u, i) = w_0 + \\sum_{j=1}^{d} w_j * x_j\n",
    "        out = self.feat_weight(x[:, 2:])\n",
    "        users = x[:, 0].to(dtype=torch.int32)\n",
    "        items = x[:, 1].to(dtype=torch.int32)\n",
    "        out += self.user_weight(users)\n",
    "        out += self.item_weight(items)\n",
    "        # Nested summation thingy\n",
    "        # Interactions between users/items and features\n",
    "        u_embed = self.user_latent(users)\n",
    "        i_embed = self.item_latent(items)\n",
    "        f_embed = self.feat_latent(torch.Tensor(range(0, self.n_feature)).to(device, dtype=torch.int32))\n",
    "        out += (u_embed * i_embed).sum(dim=1).unsqueeze(-1)   # Dot product between user and item latent representations\n",
    "        out += (u_embed @ f_embed.T).sum(dim=1).unsqueeze(-1) # Dot product between user and feature latent representations\n",
    "        out += (i_embed @ f_embed.T).sum(dim=1).unsqueeze(-1) # Dot product between item and feature latent representations\n",
    "        # Interactions between features\n",
    "        for i in range(0, self.n_feature):\n",
    "            for j in range(0, i):\n",
    "                out += (f_embed[i] @ f_embed[j].T) * (x[:, 2 + i] * x[:, 2 + j]).unsqueeze(-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Played Prediction/Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_model = FactorizationMachine(len(df['userID'].unique()), len(df['itemID'].unique()), 24, 16).to(device)\n",
    "played_dl = DataLoader(dataset=played_ds,\n",
    "                       batch_size=20,\n",
    "                       num_workers=4)\n",
    "optimizer = optim.RMSprop(played_model.parameters(), lr=0.001, weight_decay=0.2)\n",
    "def BPRLoss(pos_score, neg_score):\n",
    "     return -(pos_score - neg_score).sigmoid().log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-97.3292]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "played_model(played_ds[0][0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/7500\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "for i, (pos, neg) in enumerate(played_dl):\n",
    "    print(f\"{i}/{len(played_dl)}\")\n",
    "    pos_score = played_model(pos.to(device))\n",
    "    neg_score = played_model(neg.to(device))\n",
    "    loss = BPRLoss(pos_score, neg_score)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"ACU: {torch.sum(pos_score > neg_score) / len(pos_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

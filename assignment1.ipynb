{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258: Assignment 1\n",
    "### Benjamin Xia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:19.717930300Z",
     "start_time": "2023-10-26T01:59:57.594733500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn import preprocessing, feature_extraction, linear_model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from rankfm.rankfm import RankFM\n",
    "from fastFM import als, sgd\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "valid = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user/item ID's, compensation, early_access, and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:53.408937700Z",
     "start_time": "2023-10-26T02:00:34.962524200Z"
    }
   },
   "outputs": [],
   "source": [
    "user_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5, handle_unknown='error')\n",
    "item_oe = preprocessing.OrdinalEncoder(dtype=np.int32)\n",
    "\n",
    "itemset = set() # Set of all unique users\n",
    "userset = set() # Set of all unique items\n",
    "\n",
    "ft = ['early_access', 'compensation'] # features unavailable/cannot be approximated in inference\n",
    "\n",
    "def read_json(path):\n",
    "    f: gzip.GzipFile = gzip.open(path)\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = eval(line)\n",
    "        yield entry\n",
    "\n",
    "# Encode userID and itemID as integers\n",
    "def process_data():\n",
    "    data = []\n",
    "    data = []\n",
    "    for entry in read_json('train.json.gz'):\n",
    "        data.append(entry)\n",
    "    df: pd.DataFrame = pd.DataFrame(data)\n",
    "    del data\n",
    "\n",
    "    df['userIDX'] = user_oe.fit_transform(df[['userID']])\n",
    "    df['itemIDX'] = item_oe.fit_transform(df[['gameID']])\n",
    "    df.rename({'gameID' : 'itemID'}, axis=1, inplace=True)\n",
    "\n",
    "    df.drop(labels=['hours', 'user_id', 'date', 'userID', 'itemID'], axis=1, inplace=True)\n",
    "\n",
    "    # Get features that won't be available\n",
    "    df.fillna(value=0, axis=1, inplace=True)\n",
    "    df['compensation'] = df['compensation'].map(lambda x : x if x == 0 else 1)\n",
    "    df[['early_access', 'compensation']] = df[['early_access', 'compensation']].astype(np.int32)\n",
    "\n",
    "    time_label = df['hours_transformed'].to_numpy()\n",
    "    user_mean_ft = df.groupby('userIDX')[ft].mean()\n",
    "    item_mean_ft = df.groupby('itemIDX')[ft].mean()\n",
    "    df.drop(labels=ft + ['hours_transformed', 'found_funny'], axis=1, inplace=True)\n",
    "    return df, time_label, user_mean_ft.to_numpy(), item_mean_ft.to_numpy()\n",
    "\n",
    "df, time_label, user_mean_ft, item_mean_ft = process_data()\n",
    "\n",
    "def get_text_embedding():\n",
    "    if not os.path.isfile('./text_embed.npy'): # Generate new descriptors for each review using pretrained transformer\n",
    "        dftext = df.groupby('itemIDX')['text'].apply(' '.join).reset_index()\n",
    "        counter = feature_extraction.text.CountVectorizer(min_df=0.05, max_df=0.5, stop_words='english', max_features=2000, ngram_range=(1, 2))\n",
    "        wordcount = counter.fit_transform(dftext['text'])\n",
    "        LDA = LatentDirichletAllocation(n_components=20, random_state=RANDOM_SEED)\n",
    "        text_embed = LDA.fit_transform(wordcount)\n",
    "        np.save('text_embed.npy', text_embed)\n",
    "    else: # Text descriptors already computed\n",
    "        text_embed = np.load('./text_embed.npy')\n",
    "\n",
    "    return text_embed\n",
    "\n",
    "text_embed = get_text_embedding()\n",
    "text_embed = text_embed / np.linalg.norm(text_embed, axis=1)[...,None]\n",
    "df.drop('text', axis=1, inplace=True)\n",
    "pairs = df[['userIDX', 'itemIDX']].to_numpy(dtype=np.int32)\n",
    "item_ft = np.concatenate((np.arange(0, len(text_embed))[:,  None], item_mean_ft, text_embed, df['itemIDX'].value_counts().sort_index().to_numpy()[:, None] / np.max(df['itemIDX'].value_counts())), axis=1)\n",
    "\n",
    "U = dict(df.groupby('itemIDX')['userIDX'].unique())\n",
    "I = dict(df.groupby('userIDX')['itemIDX'].unique())\n",
    "U = { g : set(U[g]) for g in U }\n",
    "I = { u : set(I[u]) for u in I }\n",
    "itemset = set(df['itemIDX'].unique())\n",
    "userset = set(df['userIDX'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Played Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new validation set w/ negative pairs\n",
    "def gen_neg_samples(pairs):\n",
    "    neg_pairs = np.zeros_like(pairs)\n",
    "    neg_pairs[:, 0] = pairs[:, 0]\n",
    "\n",
    "    for i in range(len(pairs)):\n",
    "        sample = random.sample(itemset.difference(I[pairs[i, 0]]), k=1)[0]\n",
    "        neg_pairs[i, 1] = sample\n",
    "\n",
    "    return neg_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Played Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 72.01142857142857%\n",
      "Fold 2: 72.13142857142857%\n",
      "Fold 3: 73.52%\n",
      "Fold 4: 72.34857142857143%\n",
      "Fold 5: 72.77714285714286%\n",
      "Fold 6: 71.88%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Train Models\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m played_model \u001b[39m=\u001b[39m RankFM(factors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbpr\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m             max_samples\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m             beta\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m             learning_schedule\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minvscaling\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m played_model\u001b[39m.\u001b[39;49mfit(pairs[train], item_features\u001b[39m=\u001b[39;49mitem_ft, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m pos_scores \u001b[39m=\u001b[39m played_model\u001b[39m.\u001b[39mpredict(pos_train_pairs)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m neg_scores \u001b[39m=\u001b[39m played_model\u001b[39m.\u001b[39mpredict(neg_train_pairs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/rankfm/rankfm.py:265\u001b[0m, in \u001b[0;36mRankFM.fit\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, verbose)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"clear previous model state and learn new model weights using the input data\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m \u001b[39m:param interactions: dataframe of observed user/item interactions: [user_id, item_id]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m:return: self\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset_state()\n\u001b[0;32m--> 265\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_partial(interactions, user_features, item_features, sample_weight, epochs, verbose)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/rankfm/rankfm.py:303\u001b[0m, in \u001b[0;36mRankFM.fit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, verbose)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m[loss] function not recognized\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    302\u001b[0m \u001b[39m# NOTE: the cython internal fit method updates the model weights in place via memoryviews\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m _fit(\n\u001b[1;32m    304\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minteractions,\n\u001b[1;32m    305\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_weight,\n\u001b[1;32m    306\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_items,\n\u001b[1;32m    307\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_uf,\n\u001b[1;32m    308\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_if,\n\u001b[1;32m    309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw_i,\n\u001b[1;32m    310\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw_if,\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_u,\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_i,\n\u001b[1;32m    313\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_uf,\n\u001b[1;32m    314\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_if,\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeta,\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_schedule,\n\u001b[1;32m    319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_exponent,\n\u001b[1;32m    320\u001b[0m     max_samples,\n\u001b[1;32m    321\u001b[0m     epochs,\n\u001b[1;32m    322\u001b[0m     verbose\n\u001b[1;32m    323\u001b[0m )\n\u001b[1;32m    325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32mrankfm/_rankfm.pyx:331\u001b[0m, in \u001b[0;36mrankfm._rankfm._fit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrankfm/_rankfm.pyx:98\u001b[0m, in \u001b[0;36mrankfm._rankfm.assert_finite\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=20, shuffle=True, random_state=RANDOM_SEED)\n",
    "accs = []\n",
    "for split, (train, test) in enumerate(kf.split(pairs)):\n",
    "    popularity = df.iloc[train]['itemIDX'].value_counts().sort_index().to_numpy()\n",
    "    # Generate training pairs for fold\n",
    "    pos_train_pairs = pairs[train]\n",
    "    neg_train_pairs = gen_neg_samples(pos_train_pairs)\n",
    "    pos_valid_pairs = pairs[test]\n",
    "    neg_valid_pairs = gen_neg_samples(pos_valid_pairs)\n",
    "    # Train Models\n",
    "    played_model = RankFM(factors=5,\n",
    "                loss='bpr',\n",
    "                max_samples=300,\n",
    "                beta=1.0,\n",
    "                learning_schedule='invscaling')\n",
    "    played_model.fit(pairs[train], item_features=item_ft, epochs=200)\n",
    "    pos_scores = played_model.predict(pos_train_pairs)\n",
    "    neg_scores = played_model.predict(neg_train_pairs)\n",
    "    pos_ft = popularity[pos_train_pairs[:, 1, None]]\n",
    "    neg_ft = popularity[neg_train_pairs[:, 1, None]]\n",
    "    pos_ft = np.column_stack((pos_scores, pos_ft))\n",
    "    neg_ft = np.column_stack((neg_scores, neg_ft))\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    ft = np.concatenate((pos_ft, neg_ft), axis=0)\n",
    "    label = np.concatenate((np.ones(len(pos_ft)), np.zeros(len(pos_ft))))\n",
    "    clf.fit(ft, label)\n",
    "\n",
    "    # Validation\n",
    "    pos_scores = played_model.predict(pos_valid_pairs)\n",
    "    neg_scores = played_model.predict(neg_valid_pairs)\n",
    "    pos_ft = popularity[pos_valid_pairs[:, 1, None]]\n",
    "    neg_ft = popularity[neg_valid_pairs[:, 1, None]]\n",
    "    pos_ft = np.column_stack((pos_scores, pos_ft))\n",
    "    neg_ft = np.column_stack((neg_scores, neg_ft))\n",
    "    ft = np.concatenate((pos_ft, neg_ft), axis=0)\n",
    "    label = np.concatenate((np.ones(len(pos_ft)), np.zeros(len(pos_ft))))\n",
    "    acc = clf.score(ft, label)\n",
    "    accs.append(acc)\n",
    "    print(f'Fold {split + 1}: {acc * 100}%')\n",
    "\n",
    "print(f'Overall: {np.mean(accs) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 72.99428571428571%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb Cell 11\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Generate training pairs for fold\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m pos_train_pairs \u001b[39m=\u001b[39m pairs[train]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m neg_train_pairs \u001b[39m=\u001b[39m gen_neg_samples(pos_train_pairs)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m pos_valid_pairs \u001b[39m=\u001b[39m pairs[valid]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m neg_valid_pairs \u001b[39m=\u001b[39m gen_neg_samples(pos_valid_pairs)\n",
      "\u001b[1;32m/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m neg_pairs[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m pairs[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pairs)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     sample \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(itemset\u001b[39m.\u001b[39;49mdifference(I[pairs[i, \u001b[39m0\u001b[39;49m]]), k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     neg_pairs[i, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m sample\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m neg_pairs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logistic = False\n",
    "kf = KFold(n_splits=20, shuffle=True)\n",
    "accs = []\n",
    "for split, (train, valid) in enumerate(kf.split(pairs)):\n",
    "    popularity = df.iloc[train]['itemIDX'].value_counts().sort_index().to_numpy()\n",
    "    # Generate training pairs for fold\n",
    "    pos_train_pairs = pairs[train]\n",
    "    neg_train_pairs = gen_neg_samples(pos_train_pairs)\n",
    "    pos_valid_pairs = pairs[valid]\n",
    "    neg_valid_pairs = gen_neg_samples(pos_valid_pairs)\n",
    "\n",
    "    # Fit models\n",
    "    played_model = RankFM(factors=4,\n",
    "                loss='warp',\n",
    "                max_samples=300,\n",
    "                beta=1.0,\n",
    "                learning_schedule='invscaling')\n",
    "\n",
    "    played_model.fit(pos_train_pairs, item_features=item_ft, epochs=200)\n",
    "    if logistic:\n",
    "        pos_scores = played_model.predict(pos_train_pairs)\n",
    "        neg_scores = played_model.predict(neg_train_pairs)\n",
    "        pos_ft = np.column_stack((pos_scores, popularity[pos_train_pairs[:, 1]]))\n",
    "        neg_ft = np.column_stack((neg_scores, popularity[neg_train_pairs[:, 1]]))\n",
    "        clf = linear_model.LogisticRegression()\n",
    "        ft = np.concatenate((pos_ft, neg_ft), axis=0)\n",
    "        label = np.concatenate((np.ones(len(pos_ft)), np.zeros(len(pos_ft))))\n",
    "        clf.fit(ft, label)\n",
    "\n",
    "    # Validate\n",
    "    pos_scores = played_model.predict(pos_valid_pairs)\n",
    "    neg_scores = played_model.predict(neg_valid_pairs)\n",
    "    pos_scores[np.isnan(pos_scores)] = 0\n",
    "    neg_scores[np.isnan(neg_scores)] = 0\n",
    "    if logistic:\n",
    "        pos_ft = np.column_stack((pos_scores, popularity[pos_valid_pairs[:, 1]]))\n",
    "        neg_ft = np.column_stack((neg_scores, popularity[neg_valid_pairs[:, 1]]))\n",
    "        ft = np.concatenate((pos_ft, neg_ft), axis=0)\n",
    "        label = np.concatenate((np.ones(len(pos_ft)), np.zeros(len(pos_ft))))\n",
    "        acc = clf.score(ft, label)\n",
    "    else:\n",
    "        median = np.median(np.concatenate((pos_scores, neg_scores)))\n",
    "        acc = ((np.mean(pos_scores >= median)) + (np.mean(neg_scores < median))) / 2\n",
    "\n",
    "    accs.append(acc)\n",
    "    print(f'Fold {split + 1}: {acc * 100}%')\n",
    "\n",
    "print(f'Overall: {np.mean(accs) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_model = RankFM(factors=4,\n",
    "                loss='warp',\n",
    "                max_samples=300,\n",
    "                beta=1.0,\n",
    "                learning_schedule='invscaling')\n",
    "popularity = df['itemIDX'].value_counts().sort_index().to_numpy()\n",
    "played_model.fit(pairs, item_features=item_ft, epochs=200)\n",
    "pos_scores = played_model.predict(pairs)\n",
    "neg_pairs = gen_neg_samples(pairs)\n",
    "neg_scores = played_model.predict(neg_pairs)\n",
    "pos_ft = np.column_stack((pos_scores, popularity[pairs[:, 1]]))\n",
    "neg_ft = np.column_stack((neg_scores, popularity[neg_pairs[:, 1]]))\n",
    "if logistic:\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    ft = np.concatenate((pos_ft, neg_ft), axis=0)\n",
    "    label = np.concatenate((np.ones(len(pos_ft)), np.zeros(len(pos_ft))))\n",
    "    clf.fit(ft, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./pairs_Played.csv')\n",
    "testpred = test_df.copy()\n",
    "# # Map unseen entries to default user (this user is already grouped with other users due to their few # of reviews in training set)\n",
    "test_df['userID'] = test_df['userID'].map(lambda x: x if x in user_oe.categories_[0] else 'u03473346')\n",
    "test_df['itemID'] = test_df['gameID']\n",
    "test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "test_pairs = test_df[['userIDX', 'itemIDX']].to_numpy()\n",
    "scores = played_model.predict(test_pairs)\n",
    "if logistic:\n",
    "    test_pop = popularity[test_pairs[:, 1]]\n",
    "    ft = np.column_stack((scores, test_pop))\n",
    "    scores = clf.predict_log_proba(ft)[:, 1]\n",
    "testpred = pd.read_csv('./pairs_Played.csv')\n",
    "testpred['prediction'] = scores\n",
    "medians = testpred.groupby('userID')['prediction'].median()\n",
    "preds = []\n",
    "for i, row in testpred.iterrows():\n",
    "    if scores[i] >= medians[row['userID']]:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)\n",
    "testpred['prediction'] = preds\n",
    "testpred.to_csv('./predictions_Played.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastFM,(this sucks but not as much, with or without features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (19,)  and requested shape (1,22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m datum\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m all_sparse \u001b[39m=\u001b[39m convert_sparse_df(df, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m all_sparse_ft \u001b[39m=\u001b[39m convert_sparse_df(df, \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     datum[i, \u001b[39mlen\u001b[39m(userset) \u001b[39m+\u001b[39m item] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m feat:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         datum[i, \u001b[39mlen\u001b[39;49m(userset) \u001b[39m+\u001b[39;49m \u001b[39mlen\u001b[39;49m(itemset):] \u001b[39m=\u001b[39m text_embed[item, \u001b[39m1\u001b[39m:]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m datum\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_lil.py:331\u001b[0m, in \u001b[0;36mlil_matrix.__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_intXint(key[\u001b[39m0\u001b[39m], key[\u001b[39m1\u001b[39m], x)\n\u001b[1;32m    330\u001b[0m \u001b[39m# Everything else takes the normal path.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m IndexMixin\u001b[39m.\u001b[39;49m\u001b[39m__setitem__\u001b[39;49m(\u001b[39mself\u001b[39;49m, key, x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/_index.py:142\u001b[0m, in \u001b[0;36mIndexMixin.__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m i\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mshape:\n\u001b[0;32m--> 142\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mbroadcast_to(x, i\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/stride_tricks.py:412\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbroadcast_to\u001b[39m(array, shape, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    368\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \n\u001b[1;32m    370\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m           [1, 2, 3]])\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m _broadcast_to(array, shape, subok\u001b[39m=\u001b[39;49msubok, readonly\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/stride_tricks.py:348\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall elements of broadcast shape must be non-\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    346\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mnegative\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    347\u001b[0m extras \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 348\u001b[0m it \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mnditer(\n\u001b[1;32m    349\u001b[0m     (array,), flags\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mmulti_index\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrefs_ok\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mzerosize_ok\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m extras,\n\u001b[1;32m    350\u001b[0m     op_flags\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mreadonly\u001b[39;49m\u001b[39m'\u001b[39;49m], itershape\u001b[39m=\u001b[39;49mshape, order\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    351\u001b[0m \u001b[39mwith\u001b[39;00m it:\n\u001b[1;32m    352\u001b[0m     \u001b[39m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     broadcast \u001b[39m=\u001b[39m it\u001b[39m.\u001b[39mitviews[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (19,)  and requested shape (1,22)"
     ]
    }
   ],
   "source": [
    "def convert_sparse_df(df: pd.DataFrame, feat=True):\n",
    "    if feat == True:\n",
    "        datum = sparse.lil_matrix((len(df), len(userset) + len(itemset) + 22))\n",
    "    else:\n",
    "        datum = sparse.lil_matrix((len(df), len(userset) + len(itemset)))\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        user = row['userIDX']\n",
    "        item = row['itemIDX']\n",
    "        datum[i, user] = 1\n",
    "        datum[i, len(userset) + item] = 1\n",
    "        if feat:\n",
    "            datum[i, len(userset) + len(itemset):] = text_embed[item, 1:]\n",
    "    return datum\n",
    "\n",
    "all_sparse = convert_sparse_df(df, False)\n",
    "all_sparse_ft = convert_sparse_df(df, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Model Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_iter': range(9, 13),\n",
    "#     'rank': [5],\n",
    "#     'random_state':[RANDOM_SEED],\n",
    "#     'l2_reg_w': [7.5],\n",
    "#     'l2_reg_V': [140],\n",
    "# }\n",
    "# time_model = GridSearchCV(als.FMRegression(), param_grid=param_grid, refit=True, verbose=3, n_jobs=-1, cv=5)\n",
    "# time_model.fit(all_sparse_ft, time_label)\n",
    "# time_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter = KFold(n_splits=20, shuffle=True)\n",
    "# mse = []\n",
    "# for train, test in splitter.split(all_sparse_ft):\n",
    "#     time_model2 = als.FMRegression(n_iter=10,\n",
    "#                                 rank=5,\n",
    "#                                 random_state=RANDOM_SEED,\n",
    "#                                 l2_reg_w=7.5,\n",
    "#                                 l2_reg_V=140)\n",
    "#     time_model2.fit(all_sparse_ft[train], time_label[train])\n",
    "#     preds = time_model2.predict(all_sparse_ft[test])\n",
    "#     loss = np.mean((preds - time_label[test])**2)\n",
    "#     print(loss)\n",
    "#     mse.append(loss)\n",
    "# print(f'Overall MSE: {np.mean(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_sparse_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m time_model \u001b[39m=\u001b[39m als\u001b[39m.\u001b[39mFMRegression(n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                                 rank\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                 random_state\u001b[39m=\u001b[39mRANDOM_SEED,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                                 l2_reg_w\u001b[39m=\u001b[39m\u001b[39m7.5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                 l2_reg_V\u001b[39m=\u001b[39m\u001b[39m140\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/benjx/cs_wsl/school/y3/cse258/CSE258-A1/assignment1.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m time_model\u001b[39m.\u001b[39mfit(all_sparse_ft, time_label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_sparse_ft' is not defined"
     ]
    }
   ],
   "source": [
    "time_model = als.FMRegression(n_iter=10,\n",
    "                                rank=5,\n",
    "                                random_state=RANDOM_SEED,\n",
    "                                l2_reg_w=7.5,\n",
    "                                l2_reg_V=140)\n",
    "time_model.fit(all_sparse_ft, time_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open('fastfm.obj', 'wb')\n",
    "pickle.dump(time_model, model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred = test_df.copy()\n",
    "test_df['itemID'] = test_df['gameID']\n",
    "test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "test_sparse = convert_sparse_df(test_df, True)\n",
    "preds = time_model.predict(test_sparse)\n",
    "testpred = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred['prediction'] = preds\n",
    "testpred.to_csv('./predictions_Hours.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

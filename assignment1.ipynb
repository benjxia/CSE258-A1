{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258: Assignment 1\n",
    "### Benjamin Xia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:19.717930300Z",
     "start_time": "2023-10-26T01:59:57.594733500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from rankfm.rankfm import RankFM\n",
    "from fastFM import als, sgd\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "test = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user/item ID's, compensation, early_access, and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:53.408937700Z",
     "start_time": "2023-10-26T02:00:34.962524200Z"
    }
   },
   "outputs": [],
   "source": [
    "user_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5, handle_unknown='use_encoded_value', unknown_value=6710)\n",
    "item_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5)\n",
    "\n",
    "itemset = set() # Set of all unique users\n",
    "userset = set() # Set of all unique items\n",
    "U = defaultdict(set)\n",
    "I = defaultdict(set)\n",
    "time_played = defaultdict(dict)\n",
    "item_mean_hr = defaultdict()\n",
    "user_mean_hr = defaultdict()\n",
    "ft = ['early_access', 'compensation'] # features unavailable/cannot be approximated in inference\n",
    "def read_json(path):\n",
    "    f: gzip.GzipFile = gzip.open(path)\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = eval(line)\n",
    "        yield entry\n",
    "\n",
    "# Encode userID and itemID as integers\n",
    "def process_data():\n",
    "    global itemset, userset, U, I, user_mean_hr, item_mean_hr\n",
    "    data = []\n",
    "    for entry in read_json('train.json.gz'):\n",
    "        data.append(entry)\n",
    "        time_played[entry['userID']][entry['gameID']] = entry['hours_transformed']\n",
    "\n",
    "    df: pd.DataFrame = pd.DataFrame(data)\n",
    "    del data\n",
    "    itemset = set(df['gameID'].unique())\n",
    "    userset = set(df['userID'].unique())\n",
    "\n",
    "    U = dict(df.groupby('gameID')['userID'].unique())\n",
    "    I = dict(df.groupby('userID')['gameID'].unique())\n",
    "    U = { g : set(U[g]) for g in U }\n",
    "    I = { u : set(I[u]) for u in I }\n",
    "\n",
    "    df['userIDX'] = user_oe.fit_transform(df[['userID']])\n",
    "    df['itemIDX'] = item_oe.fit_transform(df[['gameID']])\n",
    "    df.rename({'gameID' : 'itemID'}, axis=1, inplace=True)\n",
    "\n",
    "    df.drop(labels=['hours', 'user_id', 'date'], axis=1, inplace=True)\n",
    "\n",
    "    # Get features that won't be available\n",
    "    df.fillna(value=0, axis=1, inplace=True)\n",
    "    df['compensation'] = df['compensation'].map(lambda x : x if x == 0 else 1)\n",
    "    df[['early_access', 'compensation']] = df[['early_access', 'compensation']].astype(np.int32)\n",
    "\n",
    "    time_label = df['hours_transformed']\n",
    "    item_mean_hr = dict(df.groupby('itemID')['hours_transformed'].mean())\n",
    "    user_mean_hr = dict(df.groupby('userID')['hours_transformed'].mean())\n",
    "    return df, time_label\n",
    "\n",
    "df, time_label = process_data()\n",
    "user_mean_ft = df.groupby('userIDX')[ft].mean()\n",
    "item_mean_ft = df.groupby('itemIDX')[ft].mean()\n",
    "df.drop(labels=ft + ['hours_transformed', 'found_funny'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustoi = dict(df.groupby('userID')['userIDX'].unique().apply(lambda x: x[0]))\n",
    "istoi = dict(df.groupby('itemID')['itemIDX'].unique().apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user text and convert to descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embedding():\n",
    "    if not os.path.isfile('./text_embed.npy'): # Generate new descriptors for each review using pretrained transformer\n",
    "        dftext = df.groupby('itemIDX')['text'].apply(' '.join).reset_index()\n",
    "        counter = feature_extraction.text.CountVectorizer(min_df=0.05, max_df=0.5, stop_words='english', max_features=2000, ngram_range=(1, 2))\n",
    "        wordcount = counter.fit_transform(dftext['text'])\n",
    "        LDA = LatentDirichletAllocation(n_components=20, random_state=RANDOM_SEED)\n",
    "        text_embed = LDA.fit_transform(wordcount)\n",
    "        np.save('text_embed.npy', text_embed)\n",
    "    else: # Text descriptors already computed\n",
    "        text_embed = np.load('./text_embed.npy')\n",
    "\n",
    "    return text_embed\n",
    "\n",
    "text_embed = get_text_embedding()\n",
    "# text_embed = text_embed / np.linalg.norm(text_embed, axis=1)[...,None]\n",
    "\n",
    "df.drop('text', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = np.concatenate((np.arange(0, len(text_embed))[:,  None], text_embed, item_mean_ft.to_numpy()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:150000]\n",
    "df_time_train_label = time_label[:150000]\n",
    "df_valid = df.iloc[150000:]\n",
    "df_time_valid_label = time_label[150000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Played Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_model = RankFM(factors=5,\n",
    "               loss='warp',\n",
    "               max_samples=300,\n",
    "               learning_exponent=0.25,\n",
    "               learning_schedule='invscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validation stuff - determine factor dimensions\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# kf = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# for k in [1, 2, 3, 4, 5, 6, 10, 20]:\n",
    "#     played_model = RankFM(factors=k,\n",
    "#                 loss='warp',\n",
    "#                 max_samples=300,\n",
    "#                 learning_exponent=0.25,\n",
    "#                 learning_schedule='invscaling')\n",
    "#     fold_accs = []\n",
    "#     for i, (train, test) in enumerate(kf.split(df[['userIDX', 'itemIDX']])):\n",
    "#         played_model.fit(df.iloc[train][['userIDX', 'itemIDX']], item_features=text_embed, epochs=20, verbose=False)\n",
    "#         neg_pairs = []\n",
    "#         for review in df.iloc[test].iterrows():\n",
    "#             review = review[1]\n",
    "#             sample = random.sample(itemset.difference(I[review['userID']]), k=1)[0]\n",
    "#             neg_pairs.append([review['userIDX'], istoi[sample]])\n",
    "#         pos_pairs = df.iloc[test][['userIDX', 'itemIDX']].to_numpy()\n",
    "#         neg_pairs = np.array(neg_pairs)\n",
    "#         pos_scores = played_model.predict(pos_pairs)\n",
    "#         neg_scores = played_model.predict(neg_pairs)\n",
    "#         acc = (np.mean(pos_scores >= 0) + np.mean(neg_scores < 0)) / 2\n",
    "#         fold_accs.append(acc)\n",
    "#         print(f'Validation %: {acc * 100}')\n",
    "#     print(f'k: {k} = {np.mean(fold_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine training epochs\n",
    "# kf = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "# if not test:\n",
    "#     accs = np.zeros((10, 50))\n",
    "#     for j, (train, test) in enumerate(kf.split(df[['userIDX', 'itemIDX']])):\n",
    "#         played_model = RankFM(factors=5,\n",
    "#                 loss='warp',\n",
    "#                 max_samples=300,\n",
    "#                 learning_exponent=0.25,\n",
    "#                 learning_schedule='invscaling')\n",
    "#         for i in range(50):\n",
    "#             played_model.fit_partial(df.iloc[train][['userIDX', 'itemIDX']], item_features=text_embed, epochs=4, verbose=False)\n",
    "#             neg_pairs = []\n",
    "#             for review in df.iloc[test].iterrows():\n",
    "#                 review = review[1]\n",
    "#                 sample = random.sample(itemset.difference(I[review['userID']]), k=1)[0]\n",
    "#                 neg_pairs.append([review['userIDX'], istoi[sample]])\n",
    "#             pos_pairs = df.iloc[test][['userIDX', 'itemIDX']].to_numpy()\n",
    "#             neg_pairs = np.array(neg_pairs)\n",
    "#             pos_scores = played_model.predict(pos_pairs)\n",
    "#             neg_scores = played_model.predict(neg_pairs)\n",
    "#             acc = (np.mean(pos_scores >= 0) + np.mean(neg_scores < 0)) / 2\n",
    "#             print(f'Validation %: {acc * 100}')\n",
    "#             accs[j, i] = acc\n",
    "\n",
    "#     print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new validation set w/ negative pairs\n",
    "neg_pairs = []\n",
    "for review in df_valid.iterrows():\n",
    "    review = review[1]\n",
    "    sample = random.sample(itemset.difference(I[review['userID']]), k=1)[0]\n",
    "    neg_pairs.append([review['userIDX'], istoi[sample]])\n",
    "pos_pairs = df_valid[['userIDX', 'itemIDX']].to_numpy()\n",
    "neg_pairs = np.array(neg_pairs)\n",
    "\n",
    "def played_validate(model):\n",
    "    pos_scores = model.predict(pos_pairs)\n",
    "    neg_scores = model.predict(neg_pairs)\n",
    "    acc = (np.mean(pos_scores >= 0) + np.mean(neg_scores < 0)) / 2\n",
    "    print(f'Validation %: {acc * 100}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_model = RankFM(factors=5,\n",
    "               loss='warp',\n",
    "               max_samples=300,\n",
    "               learning_exponent=0.25,\n",
    "               learning_schedule='invscaling')\n",
    "train = True\n",
    "save = False\n",
    "test = True\n",
    "if train == True:\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    for i in range(50):\n",
    "        # switch fit_partial's dataframe to df_train for testing, \"df\" for actual predictions\n",
    "        if test == True:\n",
    "            played_model.fit_partial(df[['userIDX', 'itemIDX']], item_features=text_embed, epochs=4, verbose=False)\n",
    "        else:\n",
    "            played_model.fit_partial(df_train[['userIDX', 'itemIDX']], item_features=text_embed, epochs=4, verbose=False)\n",
    "        acc = played_validate(played_model)\n",
    "        if acc > best_acc:\n",
    "            best_model = copy.deepcopy(played_model)\n",
    "            best_acc = acc\n",
    "    if save == True:\n",
    "        model_file = open('rankfm.obj', 'wb')\n",
    "        pickle.dump(best_model, model_file)\n",
    "        model_file.close()\n",
    "else:\n",
    "    model_file = open('rankfm.obj', 'rb')\n",
    "    best_model = pickle.load(model_file)\n",
    "    played_model = best_model\n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_games = dict(df['itemID'].value_counts()[:int(.75 * len(df['itemID'].unique()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./pairs_Played.csv')\n",
    "testpred = test_df.copy()\n",
    "test_df['itemID'] = test_df['gameID']\n",
    "# Map unseen entries to default user (this user is already grouped with other users due to their few # of reviews in training set)\n",
    "test_df['userID'] = test_df['userID'].map(lambda x: x if x in userset else 'u03473346')\n",
    "test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "scores = best_model.predict(test_df[['userIDX', 'itemIDX']])\n",
    "testpred = pd.read_csv('./pairs_Played.csv')\n",
    "testpred['prediction'] = (scores >= np.median(scores)).astype(np.int32)\n",
    "testpred.to_csv('./predictions_Played.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df: pd.DataFrame):\n",
    "    datum = np.zeros((len(df), 10 + 10 + 22))\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        user = row['userIDX']\n",
    "        item = row['itemIDX']\n",
    "        datum[i, :10] = played_model.v_u[user]\n",
    "        datum[i, 10:20] = played_model.v_i[item]\n",
    "        datum[i, 20:] = text_embed[item, 1:]\n",
    "    return datum\n",
    "time_train = convert_df(df_train)\n",
    "time_valid = convert_df(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering with played prediction latent factors (this sucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_sim(item_i, item_j):\n",
    "#     lr_item_i = best_model.v_i[item_i]\n",
    "#     lr_item_j = best_model.v_i[item_j]\n",
    "#     return np.dot(lr_item_i, lr_item_j) / (np.linalg.norm(lr_item_i) * np.linalg.norm(lr_item_j))\n",
    "\n",
    "# def jaccard_sim(item_i, item_j):\n",
    "#     s1 = U[item_i]\n",
    "#     s2 = U[item_j]\n",
    "#     return len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "\n",
    "# def cf_predict(user_id, user_idx, item_id, item_idx):\n",
    "#     sim_sum = 0 # Sum of similarity scores (besides current)\n",
    "#     output = 0\n",
    "#     for item_j in time_played[user_id]:\n",
    "#         if item_j == item_id:\n",
    "#             continue\n",
    "#         sim = lr_sim(item_idx, istoi[item_j])\n",
    "#         # sim = jaccard_sim(item_j, item_id)\n",
    "#         score = sim * (time_played[user_id][item_j] - item_mean_hr[item_j])\n",
    "#         output += score\n",
    "#         sim_sum += np.abs(sim)\n",
    "#     if sim_sum == 0:\n",
    "#         return item_mean_hr[item_id]\n",
    "#     output /= sim_sum\n",
    "#     output += item_mean_hr[item_id]\n",
    "#     return output\n",
    "\n",
    "# preds = np.zeros((len(df_train)))\n",
    "# for i in range(len(df_train)):\n",
    "#     row = df_train.iloc[i]\n",
    "#     preds[i] = cf_predict(row['userID'], row['userIDX'], row['itemID'], row['itemIDX'])\n",
    "# print(np.mean((preds - df_time_train_label)**2))\n",
    "# preds = np.zeros((len(df_time_valid_label)))\n",
    "# for i in range(len(df_valid)):\n",
    "#     row = df_valid.iloc[i]\n",
    "#     preds[i] = cf_predict(row['userID'], row['userIDX'], row['itemID'], row['itemIDX'])\n",
    "# print(np.mean((preds - df_time_valid_label)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with played predictioin latent factors (this sucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0283774162966055\n",
      "3.3484829756518915\n"
     ]
    }
   ],
   "source": [
    "# import xgboost\n",
    "# time_model = xgboost.XGBRegressor(n_estimators=5, reg_alpha=1, gamma=1, reg_lambda=1, max_depth=10)\n",
    "# # time_model = ensemble.RandomForestRegressor(n_estimators=10, max_depth=10, max_features='sqrt', n_jobs=-1)\n",
    "# time_model.fit(time_train, df_time_train_label)\n",
    "\n",
    "# train_preds = time_model.predict(time_train)\n",
    "# # train_preds[train_preds < 0] = 0\n",
    "# # train_preds[train_preds > 14] = 14\n",
    "# print(np.mean((train_preds - df_time_train_label)**2))\n",
    "# valid_preds = time_model.predict(time_valid)\n",
    "# # valid_preds[valid_preds < 0] = 0\n",
    "# # valid_preds[valid_preds > 14] = 14\n",
    "# MSE = np.mean((valid_preds - df_time_valid_label)**2)\n",
    "# print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastFM,(this sucks but not as much, with or without features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_df(df: pd.DataFrame, feat=True):\n",
    "    if feat == True:\n",
    "        datum = sparse.lil_matrix((len(df), len(itemset) + len(userset) + 22))\n",
    "    else:\n",
    "        datum = sparse.lil_matrix((len(df), len(itemset) + len(userset)))\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        user = row['userIDX']\n",
    "        item = row['itemIDX']\n",
    "        datum[i, user] = 1\n",
    "        datum[i, len(userset) + item] = 1\n",
    "        if feat:\n",
    "            datum[i, len(userset) + len(itemset):] = text_embed[item, 1:]\n",
    "    return datum\n",
    "\n",
    "time_train = convert_sparse_df(df_train, False)\n",
    "time_valid = convert_sparse_df(df_valid, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7344737530969194\n",
      "3.080605477353974\n"
     ]
    }
   ],
   "source": [
    "time_model = als.FMRegression(n_iter=5,\n",
    "                              rank=5,\n",
    "                              init_stdev=0.001,\n",
    "                              random_state=RANDOM_SEED,\n",
    "                              l2_reg_w=0.01,\n",
    "                              l2_reg_V=75)\n",
    "time_model.fit(time_train, df_time_train_label)\n",
    "train_preds = time_model.predict(time_train)\n",
    "train_preds[train_preds < 0] = 0\n",
    "train_preds[train_preds > 14] = 14\n",
    "print(np.mean((train_preds - df_time_train_label)**2))\n",
    "valid_preds = time_model.predict(time_valid)\n",
    "valid_preds[valid_preds < 0] = 0\n",
    "valid_preds[valid_preds > 14] = 14\n",
    "MSE = np.mean((valid_preds - df_time_valid_label)**2)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HW3 Modified $\\alpha + \\beta_u + \\beta_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt', encoding='utf8')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d\n",
    "\n",
    "allHours = []\n",
    "for l in readJSON(\"train.json.gz\"):\n",
    "    allHours.append(l)\n",
    "\n",
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]\n",
    "\n",
    "# Any other preprocessing...\n",
    "itemset = set()\n",
    "userset = set()\n",
    "user_stoi = dict()\n",
    "user_itos = []\n",
    "item_stoi = dict()\n",
    "item_itos = []\n",
    "for user, item, review in allHours:\n",
    "    itemset.add(item)\n",
    "    userset.add(item)\n",
    "    if user not in user_stoi:\n",
    "        user_stoi[user] = len(user_itos)\n",
    "        user_itos.append(user)\n",
    "    if item not in item_stoi:\n",
    "        item_stoi[item] = len(item_itos)\n",
    "        item_itos.append(item)\n",
    "\n",
    "\n",
    "U = defaultdict(set)\n",
    "I = defaultdict(set)\n",
    "validPairs_part_1 = []\n",
    "for review in hoursTrain:\n",
    "    user = review[0]\n",
    "    item = review[1]\n",
    "    U[item].add(user)\n",
    "    I[user].add(item)\n",
    "\n",
    "I_arr = np.array([len(I[user_itos[u]]) for u in range(len(I))])\n",
    "U_arr = np.array([len(U[item_itos[i]]) for i in range(len(U))])\n",
    "\n",
    "validPairs_part_1 = [[user_stoi[user], item_stoi[item]] for user, item, review_body in hoursValid]\n",
    "validLabels_part_1 = np.array([1] * len(hoursValid) + [0] * len(hoursValid))\n",
    "\n",
    "validPairs_part_2 = validPairs_part_1.copy()\n",
    "validPairs_part_2 = np.array(validPairs_part_2)\n",
    "validLabels_part_2 = np.array([review['hours_transformed'] for user, item, review in hoursValid])\n",
    "\n",
    "# Construct a new validation set w/ negative pairs\n",
    "for user, item, review in hoursValid:\n",
    "    sample = random.sample(itemset.difference(I[user]), 1)[0]\n",
    "    validPairs_part_1.append([user_stoi[user], item_stoi[sample]])\n",
    "\n",
    "validPairs_part_1 = np.array(validPairs_part_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHours = np.array([r[2]['hours_transformed'] for r in hoursTrain])\n",
    "globalAverage = sum(trainHours) * 1.0 / len(trainHours)\n",
    "trainPairs = np.array([[user_stoi[user], item_stoi[item]] for user, item, review in hoursTrain])\n",
    "allPairs = np.array([[user_stoi[user], item_stoi[item]] for user, item, review in allHours])\n",
    "allHours = np.array([r[2]['hours_transformed'] for r in allHours])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form(lamb, alpha, beta_u, beta_i, train_label, train_pair):\n",
    "    new_beta_u = np.zeros_like(beta_u)\n",
    "    new_beta_i = np.zeros_like(beta_i)\n",
    "    alpha = np.mean(train_label - beta_u[train_pair[:, 0]] - beta_i[train_pair[:, 1]])\n",
    "    delta = (train_label - alpha - beta_i[train_pair[:, 1]]) / (lamb + I_arr[train_pair[:, 0]])\n",
    "    for i in range(len(train_pair)):\n",
    "        new_beta_u[train_pair[i, 0]] += delta[i]\n",
    "    beta_u = new_beta_u\n",
    "    delta = (train_label - alpha - beta_u[train_pair[:, 0]]) / (lamb + U_arr[train_pair[:, 1]])\n",
    "    for i in range(len(train_pair)):\n",
    "        new_beta_i[train_pair[i, 1]] += delta[i]\n",
    "    beta_i = new_beta_i\n",
    "    return alpha, beta_u, beta_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:02<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.990628067206146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "beta_u = np.zeros(len(I))\n",
    "beta_i = np.zeros(len(U))\n",
    "alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "\n",
    "for i in tqdm(range(200)):\n",
    "    alpha, beta_u, beta_i = closed_form(5, alpha, beta_u, beta_i, trainHours, trainPairs)\n",
    "\n",
    "validMSE = 0\n",
    "for i, (user, item) in enumerate(validPairs_part_2):\n",
    "    validMSE += (validLabels_part_2[i] - alpha - beta_u[user] - beta_i[item]) ** 2\n",
    "validMSE /= len(validPairs_part_2)\n",
    "print(validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1988,  682],\n",
       "       [ 950,  319],\n",
       "       [5165,  584],\n",
       "       ...,\n",
       "       [4844,  213],\n",
       "       [ 270,  123],\n",
       "       [2348,  997]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validPairs_part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:35<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.137118790553917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "for train, test in splitter.split(allPairs):\n",
    "    beta_u = np.zeros(len(I))\n",
    "    beta_i = np.zeros(len(U))\n",
    "    alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "\n",
    "    for i in tqdm(range(300)):\n",
    "        alpha, beta_u, beta_i = closed_form(5, alpha, beta_u, beta_i, allHours[train], allPairs[train])\n",
    "    validMSE = 0\n",
    "    for i, (user, item) in enumerate(allPairs[test]):\n",
    "        validMSE += (allHours[test][i] - alpha - beta_u[user] - beta_i[item]) ** 2\n",
    "    validMSE /= len(test)\n",
    "    print(validMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred = test_df.copy()\n",
    "test_df['itemID'] = test_df['gameID']\n",
    "# Map unseen entries to default user (this user is already grouped with other users due to their few # of reviews in training set)\n",
    "test_df['userID'] = test_df['userID'].map(lambda x: x if x in userset else 'u03473346')\n",
    "test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "\n",
    "time_test = convert_df(test_df)\n",
    "preds = time_model.predict(time_test)\n",
    "\n",
    "testpred = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred['prediction'] = preds\n",
    "testpred.to_csv('./predictions_Hours.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

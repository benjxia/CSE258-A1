{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258: Assignment 1\n",
    "### Benjamin Xia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:19.717930300Z",
     "start_time": "2023-10-26T01:59:57.594733500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from rankfm.rankfm import RankFM\n",
    "from fastFM import als, sgd\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "test = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user/item ID's, compensation, early_access, and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:00:53.408937700Z",
     "start_time": "2023-10-26T02:00:34.962524200Z"
    }
   },
   "outputs": [],
   "source": [
    "user_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5, handle_unknown='use_encoded_value', unknown_value=6710)\n",
    "item_oe = preprocessing.OrdinalEncoder(dtype=np.int32, min_frequency=5)\n",
    "\n",
    "itemset = set() # Set of all unique users\n",
    "userset = set() # Set of all unique items\n",
    "U = defaultdict(set)\n",
    "I = defaultdict(set)\n",
    "time_played = defaultdict(dict)\n",
    "item_mean_hr = defaultdict()\n",
    "user_mean_hr = defaultdict()\n",
    "ft = ['early_access', 'compensation'] # features unavailable/cannot be approximated in inference\n",
    "def read_json(path):\n",
    "    f: gzip.GzipFile = gzip.open(path)\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = eval(line)\n",
    "        yield entry\n",
    "\n",
    "# Encode userID and itemID as integers\n",
    "def process_data():\n",
    "    global itemset, userset, U, I, user_mean_hr, item_mean_hr\n",
    "    data = []\n",
    "    for entry in read_json('train.json.gz'):\n",
    "        data.append(entry)\n",
    "        time_played[entry['userID']][entry['gameID']] = entry['hours_transformed']\n",
    "\n",
    "    df: pd.DataFrame = pd.DataFrame(data)\n",
    "    del data\n",
    "    itemset = set(df['gameID'].unique())\n",
    "    userset = set(df['userID'].unique())\n",
    "\n",
    "    U = dict(df.groupby('gameID')['userID'].unique())\n",
    "    I = dict(df.groupby('userID')['gameID'].unique())\n",
    "    U = { g : set(U[g]) for g in U }\n",
    "    I = { u : set(I[u]) for u in I }\n",
    "\n",
    "    df['userIDX'] = user_oe.fit_transform(df[['userID']])\n",
    "    df['itemIDX'] = item_oe.fit_transform(df[['gameID']])\n",
    "    df.rename({'gameID' : 'itemID'}, axis=1, inplace=True)\n",
    "\n",
    "    df.drop(labels=['hours', 'user_id', 'date'], axis=1, inplace=True)\n",
    "\n",
    "    # Get features that won't be available\n",
    "    df.fillna(value=0, axis=1, inplace=True)\n",
    "    df['compensation'] = df['compensation'].map(lambda x : x if x == 0 else 1)\n",
    "    df[['early_access', 'compensation']] = df[['early_access', 'compensation']].astype(np.int32)\n",
    "\n",
    "    time_label = df['hours_transformed']\n",
    "    item_mean_hr = dict(df.groupby('itemID')['hours_transformed'].mean())\n",
    "    user_mean_hr = dict(df.groupby('userID')['hours_transformed'].mean())\n",
    "    return df, time_label\n",
    "\n",
    "df, time_label = process_data()\n",
    "user_mean_ft = df.groupby('userIDX')[ft].mean()\n",
    "item_mean_ft = df.groupby('itemIDX')[ft].mean()\n",
    "df.drop(labels=ft + ['hours_transformed', 'found_funny'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustoi = dict(df.groupby('userID')['userIDX'].unique().apply(lambda x: x[0]))\n",
    "istoi = dict(df.groupby('itemID')['itemIDX'].unique().apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess user text and convert to descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embedding():\n",
    "    if not os.path.isfile('./text_embed.npy'): # Generate new descriptors for each review using pretrained transformer\n",
    "        dftext = df.groupby('itemIDX')['text'].apply(' '.join).reset_index()\n",
    "        counter = feature_extraction.text.CountVectorizer(min_df=0.05, max_df=0.5, stop_words='english', max_features=2000, ngram_range=(1, 2))\n",
    "        wordcount = counter.fit_transform(dftext['text'])\n",
    "        LDA = LatentDirichletAllocation(n_components=20, random_state=RANDOM_SEED)\n",
    "        text_embed = LDA.fit_transform(wordcount)\n",
    "        np.save('text_embed.npy', text_embed)\n",
    "    else: # Text descriptors already computed\n",
    "        text_embed = np.load('./text_embed.npy')\n",
    "\n",
    "    return text_embed\n",
    "\n",
    "text_embed = get_text_embedding()\n",
    "# text_embed = text_embed / np.linalg.norm(text_embed, axis=1)[...,None]\n",
    "\n",
    "df.drop('text', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = np.concatenate((np.arange(0, len(text_embed))[:,  None], text_embed, item_mean_ft.to_numpy()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:150000]\n",
    "df_time_train_label = time_label[:150000]\n",
    "df_valid = df.iloc[150000:]\n",
    "df_time_valid_label = time_label[150000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Played Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_model = RankFM(factors=5,\n",
    "               loss='warp',\n",
    "               max_samples=300,\n",
    "               learning_exponent=0.25,\n",
    "               learning_schedule='invscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validation stuff - determine factor dimensions\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# kf = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# for k in [1, 2, 3, 4, 5, 6, 10, 20]:\n",
    "#     played_model = RankFM(factors=k,\n",
    "#                 loss='warp',\n",
    "#                 max_samples=300,\n",
    "#                 learning_exponent=0.25,\n",
    "#                 learning_schedule='invscaling')\n",
    "#     fold_accs = []\n",
    "#     for i, (train, test) in enumerate(kf.split(df[['userIDX', 'itemIDX']])):\n",
    "#         played_model.fit(df.iloc[train][['userIDX', 'itemIDX']], item_features=text_embed, epochs=20, verbose=False)\n",
    "#         neg_pairs = []\n",
    "#         for review in df.iloc[test].iterrows():\n",
    "#             review = review[1]\n",
    "#             sample = random.sample(itemset.difference(I[review['userID']]), k=1)[0]\n",
    "#             neg_pairs.append([review['userIDX'], istoi[sample]])\n",
    "#         pos_pairs = df.iloc[test][['userIDX', 'itemIDX']].to_numpy()\n",
    "#         neg_pairs = np.array(neg_pairs)\n",
    "#         pos_scores = played_model.predict(pos_pairs)\n",
    "#         neg_scores = played_model.predict(neg_pairs)\n",
    "#         acc = (np.mean(pos_scores >= 0) + np.mean(neg_scores < 0)) / 2\n",
    "#         fold_accs.append(acc)\n",
    "#         print(f'Validation %: {acc * 100}')\n",
    "#     print(f'k: {k} = {np.mean(fold_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine training epochs\n",
    "# kf = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "# if not test:\n",
    "#     accs = np.zeros((10, 50))\n",
    "#     for j, (train, test) in enumerate(kf.split(df[['userIDX', 'itemIDX']])):\n",
    "#         played_model = RankFM(factors=5,\n",
    "#                 loss='warp',\n",
    "#                 max_samples=300,\n",
    "#                 learning_exponent=0.25,\n",
    "#                 learning_schedule='invscaling')\n",
    "#         for i in range(50):\n",
    "#             played_model.fit_partial(df.iloc[train][['userIDX', 'itemIDX']], item_features=text_embed, epochs=4, verbose=False)\n",
    "#             neg_pairs = []\n",
    "#             for review in df.iloc[test].iterrows():\n",
    "#                 review = review[1]\n",
    "#                 sample = random.sample(itemset.difference(I[review['userID']]), k=1)[0]\n",
    "#                 neg_pairs.append([review['userIDX'], istoi[sample]])\n",
    "#             pos_pairs = df.iloc[test][['userIDX', 'itemIDX']].to_numpy()\n",
    "#             neg_pairs = np.array(neg_pairs)\n",
    "#             pos_scores = played_model.predict(pos_pairs)\n",
    "#             neg_scores = played_model.predict(neg_pairs)\n",
    "#             acc = (np.mean(pos_scores >= 0) + np.mean(neg_scores < 0)) / 2\n",
    "#             print(f'Validation %: {acc * 100}')\n",
    "#             accs[j, i] = acc\n",
    "\n",
    "#     print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new validation set w/ negative pairs\n",
    "neg_pairs = []\n",
    "for review in df_valid.iterrows():\n",
    "    review = review[1]\n",
    "    sample = random.sample(itemset.difference(I[review['userID']]), k=1)[0]\n",
    "    neg_pairs.append([review['userIDX'], istoi[sample]])\n",
    "pos_pairs = df_valid[['userIDX', 'itemIDX']].to_numpy()\n",
    "neg_pairs = np.array(neg_pairs)\n",
    "\n",
    "def played_validate(model):\n",
    "    pos_scores = model.predict(pos_pairs)\n",
    "    neg_scores = model.predict(neg_pairs)\n",
    "    acc = (np.mean(pos_scores >= 0) + np.mean(neg_scores < 0)) / 2\n",
    "    print(f'Validation %: {acc * 100}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_model = RankFM(factors=5,\n",
    "               loss='warp',\n",
    "               max_samples=300,\n",
    "               learning_exponent=0.25,\n",
    "               learning_schedule='invscaling')\n",
    "train = False\n",
    "save = False\n",
    "test = True\n",
    "if train == True:\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    for i in range(50):\n",
    "        # switch fit_partial's dataframe to df_train for testing, \"df\" for actual predictions\n",
    "        if test == True:\n",
    "            played_model.fit_partial(df[['userIDX', 'itemIDX']], item_features=text_embed, epochs=4, verbose=False)\n",
    "        else:\n",
    "            played_model.fit_partial(df_train[['userIDX', 'itemIDX']], item_features=text_embed, epochs=4, verbose=False)\n",
    "        acc = played_validate(played_model)\n",
    "        if acc > best_acc:\n",
    "            best_model = copy.deepcopy(played_model)\n",
    "            best_acc = acc\n",
    "    if save == True:\n",
    "        model_file = open('rankfm.obj', 'wb')\n",
    "        pickle.dump(best_model, model_file)\n",
    "        model_file.close()\n",
    "else:\n",
    "    model_file = open('rankfm.obj', 'rb')\n",
    "    best_model = pickle.load(model_file)\n",
    "    played_model = best_model\n",
    "    model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_games = dict(df['itemID'].value_counts()[:int(.75 * len(df['itemID'].unique()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('./pairs_Played.csv')\n",
    "# testpred = test_df.copy()\n",
    "# test_df['itemID'] = test_df['gameID']\n",
    "# # Map unseen entries to default user (this user is already grouped with other users due to their few # of reviews in training set)\n",
    "# test_df['userID'] = test_df['userID'].map(lambda x: x if x in userset else 'u03473346')\n",
    "# test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "# test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "# test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "# scores = best_model.predict(test_df[['userIDX', 'itemIDX']])\n",
    "# testpred = pd.read_csv('./pairs_Played.csv')\n",
    "# testpred['prediction'] = (scores >= np.median(scores)).astype(np.int32)\n",
    "# testpred.to_csv('./predictions_Played.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df(df: pd.DataFrame):\n",
    "    datum = np.zeros((len(df), 10 + 10 + 22))\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        user = row['userIDX']\n",
    "        item = row['itemIDX']\n",
    "        datum[i, :10] = played_model.v_u[user]\n",
    "        datum[i, 10:20] = played_model.v_i[item]\n",
    "        datum[i, 20:] = text_embed[item, 1:]\n",
    "    return datum\n",
    "time_train = convert_df(df_train)\n",
    "time_valid = convert_df(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering with played prediction latent factors (this sucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_sim(item_i, item_j):\n",
    "#     lr_item_i = best_model.v_i[item_i]\n",
    "#     lr_item_j = best_model.v_i[item_j]\n",
    "#     return np.dot(lr_item_i, lr_item_j) / (np.linalg.norm(lr_item_i) * np.linalg.norm(lr_item_j))\n",
    "\n",
    "# def jaccard_sim(item_i, item_j):\n",
    "#     s1 = U[item_i]\n",
    "#     s2 = U[item_j]\n",
    "#     return len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "\n",
    "# def cf_predict(user_id, user_idx, item_id, item_idx):\n",
    "#     sim_sum = 0 # Sum of similarity scores (besides current)\n",
    "#     output = 0\n",
    "#     for item_j in time_played[user_id]:\n",
    "#         if item_j == item_id:\n",
    "#             continue\n",
    "#         sim = lr_sim(item_idx, istoi[item_j])\n",
    "#         # sim = jaccard_sim(item_j, item_id)\n",
    "#         score = sim * (time_played[user_id][item_j] - item_mean_hr[item_j])\n",
    "#         output += score\n",
    "#         sim_sum += np.abs(sim)\n",
    "#     if sim_sum == 0:\n",
    "#         return item_mean_hr[item_id]\n",
    "#     output /= sim_sum\n",
    "#     output += item_mean_hr[item_id]\n",
    "#     return output\n",
    "\n",
    "# preds = np.zeros((len(df_train)))\n",
    "# for i in range(len(df_train)):\n",
    "#     row = df_train.iloc[i]\n",
    "#     preds[i] = cf_predict(row['userID'], row['userIDX'], row['itemID'], row['itemIDX'])\n",
    "# print(np.mean((preds - df_time_train_label)**2))\n",
    "# preds = np.zeros((len(df_time_valid_label)))\n",
    "# for i in range(len(df_valid)):\n",
    "#     row = df_valid.iloc[i]\n",
    "#     preds[i] = cf_predict(row['userID'], row['userIDX'], row['itemID'], row['itemIDX'])\n",
    "# print(np.mean((preds - df_time_valid_label)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with played predictioin latent factors (this sucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "# time_model = xgboost.XGBRegressor(n_estimators=5, reg_alpha=1, gamma=1, reg_lambda=1, max_depth=10)\n",
    "# # time_model = ensemble.RandomForestRegressor(n_estimators=10, max_depth=10, max_features='sqrt', n_jobs=-1)\n",
    "# time_model.fit(time_train, df_time_train_label)\n",
    "\n",
    "# train_preds = time_model.predict(time_train)\n",
    "# # train_preds[train_preds < 0] = 0\n",
    "# # train_preds[train_preds > 14] = 14\n",
    "# print(np.mean((train_preds - df_time_train_label)**2))\n",
    "# valid_preds = time_model.predict(time_valid)\n",
    "# # valid_preds[valid_preds < 0] = 0\n",
    "# # valid_preds[valid_preds > 14] = 14\n",
    "# MSE = np.mean((valid_preds - df_time_valid_label)**2)\n",
    "# print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastFM,(this sucks but not as much, with or without features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_df(df: pd.DataFrame, feat=True):\n",
    "    if feat == True:\n",
    "        datum = sparse.lil_matrix((len(df), len(userset) + len(itemset) + 22))\n",
    "    else:\n",
    "        datum = sparse.lil_matrix((len(df), len(userset) + len(itemset)))\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        user = row['userIDX']\n",
    "        item = row['itemIDX']\n",
    "        datum[i, user] = 1\n",
    "        datum[i, len(userset) + item] = 1\n",
    "        if feat:\n",
    "            datum[i, len(userset) + len(itemset):] = text_embed[item, 1:]\n",
    "    return datum\n",
    "\n",
    "all_sparse = convert_sparse_df(df, False)\n",
    "# time_train = convert_sparse_df(df_train, False)\n",
    "# time_valid = convert_sparse_df(df_valid, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sparse_ft = convert_sparse_df(df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94357863013606\n",
      "3.0434587495842345\n",
      "3.0924451428973003\n",
      "3.046188484344579\n",
      "3.049161147138229\n",
      "3.0350633349398173\n",
      "2.918512254284726\n",
      "3.040043039118561\n",
      "3.1353652614249876\n",
      "3.0720779678188492\n",
      "3.007827111620823\n",
      "2.983962310623775\n",
      "3.0554807879544903\n",
      "3.024678778729746\n",
      "2.9476587426724845\n",
      "3.0041425589393898\n",
      "2.9702414086738687\n",
      "3.1177891544670913\n",
      "2.9971199567056517\n",
      "3.0737602643915833\n",
      "Overall MSE: 3.0279277543233123\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=20, shuffle=True)\n",
    "mse = []\n",
    "for train, test in splitter.split(all_sparse):\n",
    "    time_model = als.FMRegression(n_iter=20,\n",
    "                                rank=4,\n",
    "                                init_stdev=0,\n",
    "                                random_state=RANDOM_SEED,\n",
    "                                l2_reg_w=5,\n",
    "                                l2_reg_V=200)\n",
    "    time_model.fit(all_sparse_ft[train], time_label[train])\n",
    "    preds = time_model.predict(all_sparse_ft[test])\n",
    "    loss = np.mean((preds - time_label[test])**2)\n",
    "    print(loss)\n",
    "    mse.append(loss)\n",
    "print(f'Overall MSE: {np.mean(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FMRegression(init_stdev=0, l2_reg_V=200, l2_reg_w=5, n_iter=20, random_state=0,\n",
       "             rank=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FMRegression</label><div class=\"sk-toggleable__content\"><pre>FMRegression(init_stdev=0, l2_reg_V=200, l2_reg_w=5, n_iter=20, random_state=0,\n",
       "             rank=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FMRegression(init_stdev=0, l2_reg_V=200, l2_reg_w=5, n_iter=20, random_state=0,\n",
       "             rank=4)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_model = als.FMRegression(n_iter=20,\n",
    "                            rank=4,\n",
    "                            init_stdev=0,\n",
    "                            random_state=RANDOM_SEED,\n",
    "                            l2_reg_w=5,\n",
    "                            l2_reg_V=200)\n",
    "time_model.fit(all_sparse_ft, time_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open('fastfm.obj', 'wb')\n",
    "pickle.dump(time_model, model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred = test_df.copy()\n",
    "test_df['itemID'] = test_df['gameID']\n",
    "# Map unseen entries to default user (this user is already grouped with other users due to their few # of reviews in training set)\n",
    "test_df['userID'] = test_df['userID'].map(lambda x: x if x in userset else 'u03473346')\n",
    "test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "test_sparse = convert_sparse_df(test_df, True)\n",
    "preds = time_model.predict(test_sparse)\n",
    "testpred = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred['prediction'] = preds\n",
    "testpred.to_csv('./predictions_Hours.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HW3 Modified $\\alpha + \\beta_u + \\beta_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt', encoding='utf8')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d\n",
    "\n",
    "allHours = []\n",
    "for l in readJSON(\"train.json.gz\"):\n",
    "    allHours.append(l)\n",
    "\n",
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]\n",
    "\n",
    "# Any other preprocessing...\n",
    "itemset = set()\n",
    "userset = set()\n",
    "user_stoi = dict()\n",
    "user_itos = []\n",
    "item_stoi = dict()\n",
    "item_itos = []\n",
    "for user, item, review in allHours:\n",
    "    itemset.add(item)\n",
    "    userset.add(item)\n",
    "    if user not in user_stoi:\n",
    "        user_stoi[user] = len(user_itos)\n",
    "        user_itos.append(user)\n",
    "    if item not in item_stoi:\n",
    "        item_stoi[item] = len(item_itos)\n",
    "        item_itos.append(item)\n",
    "\n",
    "\n",
    "U = defaultdict(set)\n",
    "I = defaultdict(set)\n",
    "validPairs_part_1 = []\n",
    "for review in hoursTrain:\n",
    "    user = review[0]\n",
    "    item = review[1]\n",
    "    U[item].add(user)\n",
    "    I[user].add(item)\n",
    "\n",
    "I_arr = np.array([len(I[user_itos[u]]) for u in range(len(I))])\n",
    "U_arr = np.array([len(U[item_itos[i]]) for i in range(len(U))])\n",
    "\n",
    "validPairs_part_1 = [[user_stoi[user], item_stoi[item]] for user, item, review_body in hoursValid]\n",
    "validLabels_part_1 = np.array([1] * len(hoursValid) + [0] * len(hoursValid))\n",
    "\n",
    "validPairs_part_2 = validPairs_part_1.copy()\n",
    "validPairs_part_2 = np.array(validPairs_part_2)\n",
    "validLabels_part_2 = np.array([review['hours_transformed'] for user, item, review in hoursValid])\n",
    "\n",
    "# Construct a new validation set w/ negative pairs\n",
    "for user, item, review in hoursValid:\n",
    "    sample = random.sample(itemset.difference(I[user]), 1)[0]\n",
    "    validPairs_part_1.append([user_stoi[user], item_stoi[sample]])\n",
    "\n",
    "validPairs_part_1 = np.array(validPairs_part_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHours = np.array([r[2]['hours_transformed'] for r in hoursTrain])\n",
    "globalAverage = sum(trainHours) * 1.0 / len(trainHours)\n",
    "trainPairs = np.array([[user_stoi[user], item_stoi[item]] for user, item, review in hoursTrain])\n",
    "allPairs = np.array([[user_stoi[user], item_stoi[item]] for user, item, review in allHours])\n",
    "allHours = np.array([r[2]['hours_transformed'] for r in allHours])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form(lamb, alpha, beta_u, beta_i, train_label, train_pair):\n",
    "    new_beta_u = np.zeros_like(beta_u)\n",
    "    new_beta_i = np.zeros_like(beta_i)\n",
    "    alpha = np.mean(train_label - beta_u[train_pair[:, 0]] - beta_i[train_pair[:, 1]])\n",
    "    delta = (train_label - alpha - beta_i[train_pair[:, 1]]) / (lamb + I_arr[train_pair[:, 0]])\n",
    "    for i in range(len(train_pair)):\n",
    "        new_beta_u[train_pair[i, 0]] += delta[i]\n",
    "    beta_u = new_beta_u\n",
    "    delta = (train_label - alpha - beta_u[train_pair[:, 0]]) / (lamb + U_arr[train_pair[:, 1]])\n",
    "    for i in range(len(train_pair)):\n",
    "        new_beta_i[train_pair[i, 1]] += delta[i]\n",
    "    beta_i = new_beta_i\n",
    "    return alpha, beta_u, beta_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_u = np.zeros(len(I))\n",
    "beta_i = np.zeros(len(U))\n",
    "alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "\n",
    "for i in tqdm(range(200)):\n",
    "    alpha, beta_u, beta_i = closed_form(5, alpha, beta_u, beta_i, trainHours, trainPairs)\n",
    "\n",
    "validMSE = 0\n",
    "for i, (user, item) in enumerate(validPairs_part_2):\n",
    "    validMSE += (validLabels_part_2[i] - alpha - beta_u[user] - beta_i[item]) ** 2\n",
    "validMSE /= len(validPairs_part_2)\n",
    "print(validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validPairs_part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:02<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1313159947587437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:16<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.109039617855481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:13<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9960279186243772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:14<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.015492492958487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:14<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.068044382241175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:20<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0801758005220976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:51<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.057216969825346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:09<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.996167472536808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:02<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1074313082027643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:53<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9801034424306616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:58<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9804451110849977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:08<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.099206030630063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:01<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0148692213533903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:05<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0613466351492535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:56<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0147315354624658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:15<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.922929596935045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:11<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0260520917178453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:04<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.026026815316726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:17<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.962283896896424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.054626876527155\n",
      "Overall MSE: 3.0351766605514654\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=20, shuffle=True, random_state=RANDOM_SEED)\n",
    "mselist = []\n",
    "for train, test in splitter.split(allPairs):\n",
    "    beta_u = np.zeros(len(I))\n",
    "    beta_i = np.zeros(len(U))\n",
    "    alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "\n",
    "    for i in tqdm(range(300)):\n",
    "        alpha, beta_u, beta_i = closed_form(5, alpha, beta_u, beta_i, allHours[train], allPairs[train])\n",
    "    validMSE = 0\n",
    "    for i, (user, item) in enumerate(allPairs[test]):\n",
    "        validMSE += (allHours[test][i] - alpha - beta_u[user] - beta_i[item]) ** 2\n",
    "    validMSE /= len(test)\n",
    "    mselist.append(validMSE)\n",
    "    print(validMSE)\n",
    "print(f'Overall MSE: {np.mean(mselist)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = KFold(n_splits=10, shuffle=True)\n",
    "for train, test in splitter.split(all_sparse):\n",
    "    time_model = als.FMRegression(n_iter=5,\n",
    "                                rank=0,\n",
    "                                init_stdev=0,\n",
    "                                random_state=RANDOM_SEED,\n",
    "                                l2_reg_w=0.1,\n",
    "                                l2_reg_V=0)\n",
    "    time_model.fit(all_sparse[train], time_label[train])\n",
    "    preds = time_model.predict(all_sparse[test])\n",
    "    print(np.mean((preds - time_label[test])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred = test_df.copy()\n",
    "test_df['itemID'] = test_df['gameID']\n",
    "# Map unseen entries to default user (this user is already grouped with other users due to their few # of reviews in training set)\n",
    "test_df['userID'] = test_df['userID'].map(lambda x: x if x in userset else 'u03473346')\n",
    "test_df['userIDX'] = user_oe.transform(test_df[['userID']])\n",
    "test_df['itemIDX'] = item_oe.transform(test_df[['gameID']])\n",
    "test_df.drop(columns=['gameID', 'prediction'], inplace=True)\n",
    "\n",
    "time_test = convert_df(test_df)\n",
    "preds = time_model.predict(time_test)\n",
    "\n",
    "testpred = pd.read_csv('./pairs_Hours.csv')\n",
    "testpred['prediction'] = preds\n",
    "testpred.to_csv('./predictions_Hours.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
